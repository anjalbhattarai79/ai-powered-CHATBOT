# ğŸ¤– AI-Powered Chatbot (LangGraph RAG demo)

ğŸ”— Live demo: https://ai-powered-chatbot-cy18.onrender.com

## ğŸš€ Quick overview
- ğŸ–¥ï¸ Web UI built with Streamlit (`streamlit_rag_frontend.py`).
- ğŸ”§ Backend: `langgraph_rag_backend.py` â€” implements RAG + tool-enabled agent.
- ğŸ§° Tools available: calculator (calc), DuckDuckGo web search, and PDF RAG (index & QA).
- ğŸ§  LLM: Gemini / Google Generative AI (configured in backend).

## ğŸ§© What `langgraph_rag_backend.py` does (brief)
- `chatbot`: main agent interface â€” supports streaming and emits AIMessage, HumanMessage, ToolMessage. Accepts message payloads and config (e.g., thread_id).
- `ingest_pdf(bytes, thread_id, filename)`: indexes uploaded PDFs (chunking, embedding, storing metadata).
- `retrieve_all_threads()`: returns past thread IDs for the sidebar.
- `thread_document_metadata(thread_id)`: returns last indexed doc metadata (filename, chunks, pages).
- The backend wires a vectorstore retriever with an agent + toolset â€” inspect it to change embeddings, storage, or tools.

## ğŸ–¼ï¸ Screenshot / UI preview



 Get Acces to : **Screenshot-2025-12-03-123742.jpg**


Short visual description of the UI (how it looks) ğŸ¨
- Left sidebar:
  - Title + current Thread ID ğŸ§¾
  - "New Chat" button â•
  - PDF uploader (index per-thread) ğŸ“„
  - List of past threads (buttons) ğŸ”
  - Current indexed PDF summary (filename, chunks, pages) âœ…
- Main area:
  - App title at top (e.g., "Multi Utility Chatbot") ğŸ·ï¸
  - Chat messages rendered in conversation style (user/assistant) ğŸ’¬
  - Streamed assistant responses with tool usage indicator (status box) âš™ï¸
  - Chat input at bottom to send queries âœï¸

## ğŸ› ï¸ Local installation (Windows) â€” concise
1. Install Python 3.10+.
2. Clone repo and open PowerShell/CMD in project folder.
3. Create & activate venv:
   - python -m venv .venv
   - PowerShell: .\.venv\Scripts\Activate.ps1
   - CMD: .\.venv\Scripts\activate.bat
4. Install dependencies:
   - pip install -r requirements.txt
5. Set environment variables (Gemini / Google AI):
   - PowerShell:
     $env:GEMINI_API_KEY="your_api_key"
     $env:GOOGLE_APPLICATION_CREDENTIALS="C:\path\to\service-account.json"
   - CMD:
     set GEMINI_API_KEY=your_api_key
     set GOOGLE_APPLICATION_CREDENTIALS=C:\path\to\service-account.json
6. Run:
   - streamlit run streamlit_rag_frontend.py --server.port 8501
   - Open http://localhost:8501

## ğŸ’¡ Usage notes
- Upload a PDF in the sidebar to index it for the current thread ğŸ“.
- Ask questions in the chat input â€” the agent may call tools (calc, DuckDuckGo) and stream tool usage ğŸ”„.
- "New Chat" creates a fresh thread_id; click past-thread buttons to load history.

## âœï¸ Example prompts
- "Summarize the uploaded document." ğŸ“
- "Find references to 'pricing' and summarize." ğŸ”
- "Calculate: 345*12" ğŸ§®
- "Search web for 'current LangChain release'." ğŸŒ

## âš ï¸ Troubleshooting
- Async loop errors: ensure correct Python interpreter (activated venv). The frontend attempts to set an event loop for Streamlit.
- Missing API creds: set env vars and restart Streamlit.
- Import issues: ensure `langgraph_rag_backend.py` is reachable (same folder or PYTHONPATH).
- Embeddings/vectorstore failures: check provider config and storage paths.

## ğŸ” Extending / debugging
- Add/change tools or modify the agent in `langgraph_rag_backend.py`.
- Change LLM settings (model, temperature) in backend LLM client creation.
- Keep API keys out of source control.

## ğŸ“ Live demo
- https://ai-powered-chatbot-cy18.onrender.com
